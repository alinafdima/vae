{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import data\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define flags\n",
    "\n",
    "flags = tf.app.flags\n",
    "FLAGS = flags.FLAGS\n",
    "flags.DEFINE_string('DATA_DIR', '/tmp/data/', 'Directory for storing data')\n",
    "flags.DEFINE_string('MODEL_PATH', 'models/model.ckpt', 'Path to the parameters of the trained model')\n",
    "\n",
    "flags.DEFINE_integer('INPUT_SIZE', 784, 'Size of the input image')\n",
    "flags.DEFINE_integer('HIDDEN_ENCODER_SIZE', 400, 'Size of the hidden layer in the encoder')\n",
    "flags.DEFINE_integer('HIDDEN_DECODER_SIZE', 400, 'Size of the hidden layer in the decoder')\n",
    "flags.DEFINE_integer('LATENT_SPACE_SIZE', 20, 'Size of the latent space ')\n",
    "\n",
    "flags.DEFINE_float('ADAGRAD_LR', 0.01, 'Learning rate Adagrad')   # Try with {0.01, 0.02, 0.1}\n",
    "flags.DEFINE_integer('MINIBATCH_SIZE', 100, 'Size of minibatch')\n",
    "flags.DEFINE_integer('NUMBER_ITERATIONS', 1000, 'Number of iterations for optimization')\n",
    "\n",
    "flags.DEFINE_float('INIT_STD_DEV', 0.01, 'Standard deviation for the truncated normal used for initializing the weights')\n",
    "\n",
    "flags.DEFINE_boolean('TRAIN', False, 'If False, uses saved parameters instead of training')\n",
    "flags.DEFINE_boolean('TEST', True, 'If False, does not do testing')\n",
    "\n",
    "\n",
    "flags.DEFINE_integer('NO_IMG_TO_SHOW', 10, 'Number of images to show in tensorboard')\n",
    "flags.DEFINE_integer('NUMBER_IMAGES_GENERATED', 5, 'Number of images to generate from noise')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(FLAGS.DATA_DIR, one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Helpers\n",
    "\n",
    "def create_W(shape):\n",
    "    return tf.Variable(tf.truncated_normal(shape, stddev=FLAGS.INIT_STD_DEV))\n",
    "\n",
    "def create_b(shape):\n",
    "    return tf.Variable(tf.zeros(shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define Layers\n",
    "\n",
    "# Input\n",
    "x = tf.placeholder(tf.float32, [None, FLAGS.INPUT_SIZE])\n",
    "\n",
    "# Encoder\n",
    "W_x_h_enc = create_W([FLAGS.INPUT_SIZE, FLAGS.HIDDEN_ENCODER_SIZE])\n",
    "b_x_h_enc = create_b([FLAGS.HIDDEN_ENCODER_SIZE])\n",
    "h_enc = tf.tanh(tf.add(tf.matmul(x, W_x_h_enc), b_x_h_enc))\n",
    "\n",
    "W_h_mu_enc = create_W([FLAGS.HIDDEN_ENCODER_SIZE, FLAGS.LATENT_SPACE_SIZE])\n",
    "b_h_mu_enc = create_b([FLAGS.LATENT_SPACE_SIZE])\n",
    "mu_enc = tf.tanh(tf.add(tf.matmul(h_enc, W_h_mu_enc), b_h_mu_enc))\n",
    "\n",
    "W_h_logsigma2_enc = create_W([FLAGS.HIDDEN_ENCODER_SIZE, FLAGS.LATENT_SPACE_SIZE])\n",
    "b_h_logsigma2_enc = create_b([FLAGS.LATENT_SPACE_SIZE])\n",
    "logsigma2_enc = tf.tanh(tf.add(tf.matmul(h_enc, W_h_logsigma2_enc), b_h_logsigma2_enc))\n",
    "\n",
    "# Sampler\n",
    "eps_enc = tf.random_normal(shape=tf.shape(mu_enc))\n",
    "sigma_enc = tf.exp(0.5 * logsigma2_enc)\n",
    "z = tf.add(tf.mul(sigma_enc, eps_enc), mu_enc)\n",
    "\n",
    "# Decoder\n",
    "W_z_h_dec = create_W([FLAGS.LATENT_SPACE_SIZE, FLAGS.HIDDEN_DECODER_SIZE])\n",
    "b_z_h_dec = create_b([FLAGS.HIDDEN_DECODER_SIZE])\n",
    "h_dec = tf.tanh(tf.add(tf.matmul(z, W_z_h_dec), b_z_h_dec))\n",
    "\n",
    "W_h_x_dec = create_W([FLAGS.HIDDEN_DECODER_SIZE, FLAGS.INPUT_SIZE])\n",
    "b_h_x_dec = create_b([FLAGS.INPUT_SIZE])\n",
    "x_dec = tf.add(tf.matmul(h_dec, W_h_x_dec), b_h_x_dec)\n",
    "\n",
    "log_p_x_z = tf.reduce_sum(-tf.nn.sigmoid_cross_entropy_with_logits(x_dec, x), reduction_indices=1)\n",
    "KL_q_z_x_vs_p_z = - 0.5 * tf.reduce_sum(1 + logsigma2_enc - tf.square(mu_enc) - tf.square(sigma_enc) , reduction_indices=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lower_bound = - KL_q_z_x_vs_p_z + log_p_x_z\n",
    "loss = - tf.reduce_mean(lower_bound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_it = tf.train.AdagradOptimizer(learning_rate=FLAGS.ADAGRAD_LR).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Summaries\n",
    "loss_summ = tf.scalar_summary(\"loss\", loss)\n",
    "\n",
    "reshaped_x_init = tf.reshape(x, [FLAGS.MINIBATCH_SIZE, 28, 28, 1])\n",
    "image_input_summ = tf.image_summary(\"image_input\", reshaped_x_init, FLAGS.NO_IMG_TO_SHOW)\n",
    "\n",
    "reshaped_x_dec = tf.reshape(x_dec, [FLAGS.MINIBATCH_SIZE, 28, 28, 1])\n",
    "image_dec_summ = tf.image_summary(\"image_dec\", reshaped_x_dec, FLAGS.NO_IMG_TO_SHOW)\n",
    "\n",
    "reshaped_x_gen = tf.reshape(x_dec, [FLAGS.NUMBER_IMAGES_GENERATED, 28, 28, 1])\n",
    "image_gen_summ = tf.image_summary(\"image_gen\", reshaped_x_gen, FLAGS.NUMBER_IMAGES_GENERATED)\n",
    "\n",
    "summary = tf.merge_all_summaries()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add ops to save and restore all the variables.\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing phase.\n",
      "Model restored.\n",
      "Generating images.\n",
      "Done.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Training, Testing\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    summary_writer = tf.train.SummaryWriter('logs', graph=sess.graph)\n",
    "    \n",
    "    if FLAGS.TRAIN:\n",
    "        print(\"Training phase.\")\n",
    "        if os.path.isfile(FLAGS.MODEL_PATH):\n",
    "            os.remove(FLAGS.MODEL_PATH)\n",
    "            print(\"Old model removed.\")\n",
    "            \n",
    "        sess.run(tf.initialize_all_variables())\n",
    "        print(\"Initialize parameters.\")\n",
    "        \n",
    "        for it in xrange(FLAGS.NUMBER_ITERATIONS):\n",
    "            minibatch = mnist.train.next_batch(FLAGS.MINIBATCH_SIZE)[0]\n",
    "            cur_train_it, cur_loss_summ, cur_loss = sess.run([train_it, loss_summ, loss], feed_dict={x: minibatch})\n",
    "            summary_writer.add_summary(cur_loss_summ, it)\n",
    "\n",
    "            if (it + 1) % 50 == 0 or (it + 1) == FLAGS.NUMBER_ITERATIONS:\n",
    "                saver.save(sess, FLAGS.MODEL_PATH)\n",
    "                print(\"Iteration {0} | Loss: {1}\".format(it + 1, cur_loss))\n",
    "        print(\"\")\n",
    "        \n",
    "    if FLAGS.TEST:\n",
    "        print(\"Testing phase.\")\n",
    "        if not os.path.isfile(FLAGS.MODEL_PATH):\n",
    "            print(\"No model found. Please add training phase.\")\n",
    "        else:    \n",
    "            saver.restore(sess, FLAGS.MODEL_PATH)\n",
    "            print(\"Model restored.\")\n",
    "            \n",
    "            x_init = mnist.test.next_batch(FLAGS.MINIBATCH_SIZE)[0]\n",
    "            cur_x_dec, cur_image_input_summ, cur_image_dec_summ = sess.run([x_dec, image_input_summ, image_dec_summ], feed_dict={x: x_init})\n",
    "            \n",
    "            summary_writer.add_summary(cur_image_input_summ)\n",
    "            summary_writer.add_summary(cur_image_dec_summ)\n",
    "                \n",
    "            print(\"Generating images.\")\n",
    "            z_noise = np.random.randn(FLAGS.NUMBER_IMAGES_GENERATED,FLAGS.LATENT_SPACE_SIZE)\n",
    "            x_generated, cur_image_gen_summ = sess.run([x_dec, image_gen_summ], feed_dict={z: z_noise})\n",
    "            \n",
    "            summary_writer.add_summary(cur_image_gen_summ)\n",
    "\n",
    "            \n",
    "        print(\"Done.\\n\")    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
